import cv2
import mediapipe as mp
import time
from gesture_logic import GestureController

def main():
    # åˆå§‹åŒ– MediaPipe
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(
        max_num_hands=1,  # å»ºè­°å…ˆå–®æ‰‹ï¼Œé¿å…é‚è¼¯æ‰“æ¶ï¼Œè‹¥éœ€é›™æ‰‹å¯æ”¹ç‚º 2
        min_detection_confidence=0.7,
        min_tracking_confidence=0.7
    )

    # åˆå§‹åŒ–æ§åˆ¶å™¨
    controller = GestureController()
    
    cap = cv2.VideoCapture(0)
    
    print("=== YouTube æ‰‹å‹¢æ§åˆ¶ç³»çµ±å•Ÿå‹• ===")
    print("1. â˜ï¸ + é»æ“Š : æ’­æ”¾/æš«åœ")
    print("2. â˜ï¸ å·¦å³æŒ‡ : å¿«è½‰/å€’é€€")
    print("3. ğŸ”« è·é›¢è®Šå¤§/å° : å…¨è¢å¹•åˆ‡æ›")
    print("4. âœŠ æ¡æ‹³ 2ç§’ : å€é€Ÿåˆ‡æ›")
    print("5. âœ‹ å·¦å³æ® : ä¸Š/ä¸‹ä¸€éƒ¨å½±ç‰‡ (åˆ†å·¦å³æ‰‹)")
    print("6. âœ‹ ä¸Šä¸‹ç§» : éŸ³é‡æ§åˆ¶")
    print("7. âœ‹ éœæ­¢ 2ç§’ : éœéŸ³åˆ‡æ›")
    print("================================")

    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        # å½±åƒå‰è™•ç†
        frame = cv2.flip(frame, 1) # é¡åƒ
        h, w, c = frame.shape
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        results = hands.process(rgb_frame)
        
        # é¡¯ç¤ºå†·å»ç‹€æ…‹
        elapsed = time.time() - controller.last_action_time
        if elapsed < controller.cooldown:
            cv2.putText(frame, f"COOLDOWN ({1.0 - elapsed:.1f}s)", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        else:
            cv2.putText(frame, "READY", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        if results.multi_hand_landmarks:
            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                # ç¹ªè£½éª¨æ¶
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                
                # å–å¾—å·¦å³æ‰‹æ¨™ç±¤
                handedness = results.multi_handedness[idx].classification[0].label
                
                # è™•ç†æ‰‹å‹¢é‚è¼¯
                status = controller.process(hand_landmarks.landmark, handedness)
                
                # åœ¨æ‰‹ä¸Šé¡¯ç¤ºç›®å‰ç‹€æ…‹ (é™¤éŒ¯ç”¨)
                wrist = hand_landmarks.landmark[0]
                cx, cy = int(wrist.x * w), int(wrist.y * h)
                cv2.putText(frame, handedness, (cx, cy - 20), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

        cv2.imshow('Gesture Control', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
            
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()